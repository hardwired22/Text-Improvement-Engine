{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872e360c-cb9b-40ba-a37a-9dae08b29eb8",
   "metadata": {},
   "source": [
    "Project Task: Text Improvement Engine EN\r\n",
    "\r\n",
    "Objective:\r\n",
    "Develop a tool that analyses a given text and suggests improvements based on the similarity to a list of \"standardised\" phrases. These standardised phrases represent the ideal way certain concepts should be articulated, and the tool should recommend changes to align the input text closer to these standards.\r\n",
    "\r\n",
    "Requirements:\r\n",
    "Data Input: Create a method for the user to input the text they wish to analyse. This could be through a simple UI or via a text file in CLI.\r\n",
    "\r\n",
    "Standardised Phrases: Pre-load the tool with a list of standardised phrases (e.g., business jargon, scientific terminology, etc.).\r\n",
    "\r\n",
    "Text Analysis: Use a pre-trained language model to find phrases in the input text that are semantically similar to any of the standardised phrases. Consider using techniques like cosine similarity with word embeddings. \r\n",
    "\r\n",
    "Suggestions: Provide a list of suggestions to replace phrases in the input text with their more \"standard\" versions. Each suggestion should show the original phrase, the recommended replacement, and the similarity score.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156d419e-7f8b-40cc-baec-bbf6b284a69a",
   "metadata": {},
   "source": [
    "Проектная задача: Улучшение текста с использованием движка  RU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799d598-4d00-4ed6-8306-c2bf67e9edbf",
   "metadata": {},
   "source": [
    "\n",
    "Цель:\n",
    "\n",
    "Разработать инструмент, который анализирует данный текст и предлагает улучшения на основе сходства с набором \"стандартизированных\" фраз. Эти стандартизированные фразы представляют собой идеальный способ формулировки определенных концепций, и инструмент должен рекомендовать изменения, чтобы приблизить входной текст к этим стандартам.\n",
    "\n",
    "Требования:\n",
    "\n",
    "Ввод данных: Создать метод для ввода пользователем текста, который они хотели бы проанализировать. Это может быть через простой пользовательский интерфейс или через текстовый файл в командной строке.\n",
    "Стандартизированные фразы: Предварительно загрузите инструмент набором стандартизированных фраз (например, деловой жаргон, научная терминология и т. д.).\n",
    "\n",
    "Анализ текста: Используйте предварительно обученную языковую модель для поиска фраз во входном тексте, семантически сходных с любой из стандартизированных фраз. Рассмотрите использование техник, таких как косинусное сходство с векторами слов.\n",
    "Предложения: Предоставьте список рекомендаций по замене фраз во входном тексте на более \"стандартные\" версии. Каждое предложение должно показывать исходную фразу, рекомендуемую замену и показатель сходства.\n",
    "\n",
    "Документация: Предоставьте файл README с подробным описанием процесса установки, использованными технологиями и обоснованием своих решений по дизайну.\n",
    "Этот проект даст вам возможность продемонстрировать разнообразные навыки, включая анализ текста, семантическое сходство и качество кода, и его выполнение должно быть возможным в течение 4 часов.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e1452-07f5-4aa1-ab09-3e143a92eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c0b95-f230-4043-8318-b2da0089820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763400d-d627-4b4d-943c-4690a67d6397",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install protobuf==3.20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a70bbac-e930-488a-b3e8-9148fe62bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = pd.read_csv('D:/DATA/datasets/standardised_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dc718-9334-4fab-aa25-78ef2b548509",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8bf10-203f-4eb8-b6f9-0910d5bde2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cb51c-6ec7-45c6-9fc9-50b5825b90e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8ba6c-3cad-4e05-a48f-832b975ea0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"D:/DATA/datasets/sample_text.txt\"\n",
    "\n",
    "with open(input_file_path, \"r\") as file:\n",
    "    input_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6cf9b4-c212-4576-a2c9-5fbbd802575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ea831-a01b-439e-b968-d312a0dcc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10dd20c-038c-482a-b069-a059b7edd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "embeddings = outputs.last_hidden_state.mean(dim=1).numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6391d74-0411-4e2e-b242-13dc01cbd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_phrases = [\n",
    "    \"Optimal performance\",\n",
    "    \"Utilize resources\",\n",
    "    \"Enhance productivity\",\n",
    "    \"Conduct an analysis\",\n",
    "    \"Maintain a high standard\",\n",
    "    \"Implement best practices\",\n",
    "    \"Ensure compliance\",\n",
    "    \"Streamline operations\",\n",
    "    \"Foster innovation\",\n",
    "    \"Drive growth\",\n",
    "    \"Leverage synergies\",\n",
    "    \"Demonstrate leadership\",\n",
    "    \"Exercise due diligence\",\n",
    "    \"Maximize stakeholder value\",\n",
    "    \"Prioritize tasks\",\n",
    "    \"Facilitate collaboration\",\n",
    "    \"Monitor performance metrics\",\n",
    "    \"Execute strategies\",\n",
    "    \"Gauge effectiveness\",\n",
    "    \"Champion change\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71661cef-6b3a-4a3f-a657-10553ef96766",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "suggestions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe29ed-daf4-4f01-9a12-e27ea6baa301",
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in standardized_phrases:\n",
    "    phrase_inputs = tokenizer(phrase, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        phrase_outputs = model(**phrase_inputs)\n",
    "    phrase_embedding = phrase_outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "    similarity = np.dot(embeddings, phrase_embedding.T) / (np.linalg.norm(embeddings) * np.linalg.norm(phrase_embedding))\n",
    "    if similarity > threshold:\n",
    "        suggestions.append((input_text, phrase, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b6a9d-f6e8-4141-ad94-ee884ab20cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for suggestion in suggestions:\n",
    "    original_text, recommended_phrase, similarity_score = suggestion\n",
    "    similarity_score = similarity_score.item()\n",
    "    print(f\"Original Text: {original_text}\")\n",
    "    print(f\"Recommended Phrase: {recommended_phrase}\")\n",
    "    print(f\"Similarity Score: {similarity_score:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd7eee8-2377-4448-aba5-52d01a824550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
